{
    "seed": 3431,	
    "batch_size": 8,
    "lr": 5e-5,
    "n_epochs": 30,
    "warmup": 0.1,
    "save_steps": 10000,
    "gradient_accumulation_steps": 4,
    "total_steps": 2000000,
    "weight_decay": 0.01,
    "adam_epsilon": 1e-8,
    "adam_betas": [0.9, 0.999]
}